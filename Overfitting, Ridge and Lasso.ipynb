{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab\n",
    "import math\n",
    "import numpy as np\n",
    "import random as rn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] This non-commercial license of GraphLab Create is assigned to ssubramanian90@gmail.com and will expire on February 08, 2017. For commercial licensing options, visit https://dato.com/buy/.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-10200 - Server binary: C:\\Users\\ssubr\\Anaconda2\\envs\\dato-env\\lib\\site-packages\\graphlab\\unity_server.exe - Server log: C:\\Users\\ssubr\\AppData\\Local\\Temp\\graphlab_server_1458921435.log.0\n",
      "[INFO] GraphLab Server Version: 1.8.1\n"
     ]
    }
   ],
   "source": [
    "rn.seed(91803)\n",
    "n=30\n",
    "x=graphlab.SArray([rn.random() for i in range(n)]).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: float\n",
       "Rows: 30\n",
       "[0.009095552722691913, 0.07966496214576213, 0.11784178322693395, 0.13769715723832776, 0.17727278878141373, 0.1916994311191108, 0.2026423442654708, 0.21786195415174336, 0.2487038089427649, 0.2512838032174758, 0.289243264751499, 0.2912068165523206, 0.3112290873841299, 0.3133675913563383, 0.3397060992788279, 0.36128016886670167, 0.4070925866477364, 0.4646585555449344, 0.5400057387608802, 0.5657030541964114, 0.7213150190287124, 0.7425473353140943, 0.7523266492398751, 0.7881591434738809, 0.8066314871194551, 0.8380061087249823, 0.842404220933413, 0.9127526366082569, 0.944606759803847, 0.955411707200171]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=x.apply(lambda x:math.sin(4*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add noise to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rn.seed(1)\n",
    "e=graphlab.SArray([rn.gauss(0,1.0/3.0) for i in range(n)])\n",
    "y=y+e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: float\n",
       "Rows: 30\n",
       "[0.4657691028289499, 0.7964426955579553, 0.4762166904243817, 0.2685115081863658, 0.28708653023747643, 0.7042775644547797, 0.38397858486715386, 0.2863185778328726, 0.9050956726913648, 0.888692646577532, 1.097746233496042, 0.6140631563751847, 0.9490378029452767, 0.9284925996803823, 0.4756749447675509, 1.1714455970021094, 1.1052467742248486, 1.7552305749881358, 0.8990270968982104, 0.7217271571111419, 0.6644537289429158, 0.23682901468574138, 0.4349109106004362, -0.13289178455013648, -0.012107280541919035, 0.13254738362510274, 0.006029001718016486, -0.4448450505009305, -0.9554226689949985, -0.4804278908080471]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: float\n",
       "Rows: 30\n",
       "[0.4293949177184876, 0.48314853623325693, 0.022111936312753967, -0.25484788365721056, -0.3640577383680471, 0.010444838943905622, -0.34070105667029094, -0.47894314836750995, 0.06643732549458461, 0.04445820155286828, 0.18215610011274386, -0.3046569812451042, 0.001668427875524148, -0.021580586790895962, -0.5019430004202472, 0.17933239288701125, 0.10690370033294941, 0.7963706810802287, 0.06765639243665474, -0.04823410272164017, 0.41091905834297454, 0.06626374939780849, 0.3030103420510697, -0.12184808874417226, 0.07272393778686082, 0.34142955949567266, 0.23208234081765383, 0.042824082877618797, -0.36076934153201484, 0.14840725745368283]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=graphlab.SFrame({'X1':x,'Y':y})\n",
    "\n",
    "def plot_data(data):\n",
    "    plt.plot(data['X1'],data['Y'],'k.')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">X1</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.00909555272269</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.465769102829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0796649621458</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.796442695558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.117841783227</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.476216690424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.137697157238</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.268511508186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.177272788781</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.287086530237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.191699431119</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.704277564455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.202642344265</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.383978584867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.217861954152</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.286318577833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.248703808943</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.905095672691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.251283803217</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.888692646578</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[30 rows x 2 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tX1\tfloat\n",
       "\tY\tfloat\n",
       "\n",
       "Rows: 30\n",
       "\n",
       "Data:\n",
       "+------------------+----------------+\n",
       "|        X1        |       Y        |\n",
       "+------------------+----------------+\n",
       "| 0.00909555272269 | 0.465769102829 |\n",
       "| 0.0796649621458  | 0.796442695558 |\n",
       "|  0.117841783227  | 0.476216690424 |\n",
       "|  0.137697157238  | 0.268511508186 |\n",
       "|  0.177272788781  | 0.287086530237 |\n",
       "|  0.191699431119  | 0.704277564455 |\n",
       "|  0.202642344265  | 0.383978584867 |\n",
       "|  0.217861954152  | 0.286318577833 |\n",
       "|  0.248703808943  | 0.905095672691 |\n",
       "|  0.251283803217  | 0.888692646578 |\n",
       "+------------------+----------------+\n",
       "[30 rows x 2 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define some useful polynomial regression functions\n",
    "\n",
    "Define a function to create our features for a polynomial regression model of any degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polynomial_features(data, degree):\n",
    "    datacopy=data.copy()\n",
    "    for i in range(1, degree):\n",
    "        datacopy['X'+str(i+1)]=datacopy['X'+str(i)]*datacopy['X1']\n",
    "    return datacopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Define a function to fit a polynomiallinear regression model of degree \"deg\" to the data in \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polynomial_regression(data, degree):\n",
    "    model=graphlab.linear_regression.create(polynomial_features(data, degree),target='Y',l2_penalty=0.,l1_penalty=0.,validation_set=None, verbose=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to plot data and predictions made, since we are going to use it many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_poly_predictions(data, model):\n",
    "    plot_data(data)\n",
    "\n",
    "    # Get the degree of the polynomial\n",
    "    deg = len(model.coefficients['value'])-1\n",
    "    \n",
    "    # Create 200 points in the x axis and compute the predicted value for each point\n",
    "    x_pred = graphlab.SFrame({'X1':[i/200.0 for i in range(200)]})\n",
    "    y_pred = model.predict(polynomial_features(x_pred,deg))\n",
    "    \n",
    "    # plot predictions\n",
    "    plt.plot(x_pred['X1'], y_pred, 'g-', label='degree ' + str(deg) + ' fit')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.axis([0,1,-1.5,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that prints the polynomial coefficients in a pretty way :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_coefficients(model):    \n",
    "    # Get the degree of the polynomial\n",
    "    degree = len(model.coefficients['value'])-1\n",
    "\n",
    "    # Get learned parameters as a list\n",
    "    w = list(model.coefficients['value'])\n",
    "\n",
    "    # Numpy has a nifty function to print out polynomials in a pretty way\n",
    "    # (We'll use it, but it needs the parameters in the reverse order)\n",
    "    print 'Learned polynomial for degree ' + str(degree) + ':'\n",
    "    w.reverse()\n",
    "    print np.poly1d(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fit polynomial regression models (degree-2)\n",
    "\n",
    "we are fitting a 2nd degree polynomial to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=polynomial_regression(data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">index</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">value</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">stderr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">(intercept)</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0382833304999</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.179256323069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">X1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.5149486792</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.887610375556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">X2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">None</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-5.50721931537</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.851436821376</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[3 rows x 4 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tname\tstr\n",
       "\tindex\tstr\n",
       "\tvalue\tfloat\n",
       "\tstderr\tfloat\n",
       "\n",
       "Rows: 3\n",
       "\n",
       "Data:\n",
       "+-------------+-------+-----------------+----------------+\n",
       "|     name    | index |      value      |     stderr     |\n",
       "+-------------+-------+-----------------+----------------+\n",
       "| (intercept) |  None | 0.0382833304999 | 0.179256323069 |\n",
       "|      X1     |  None |   4.5149486792  | 0.887610375556 |\n",
       "|      X2     |  None |  -5.50721931537 | 0.851436821376 |\n",
       "+-------------+-------+-----------------+----------------+\n",
       "[3 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned polynomial for degree 2:\n",
      "        2\n",
      "-5.507 x + 4.515 x + 0.03828\n"
     ]
    }
   ],
   "source": [
    "print_coefficients(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_poly_predictions(data,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fit a degree-4 polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned polynomial for degree 4:\n",
      "       4         3        2\n",
      "26.22 x - 56.08 x + 33.4 x - 4.926 x + 0.6229\n"
     ]
    }
   ],
   "source": [
    "model4=polynomial_regression(data,4)\n",
    "print_coefficients(model4)\n",
    "plot_poly_predictions(data,model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fit a degree-16 polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned polynomial for degree 16:\n",
      "           16             15            14             13\n",
      "-5.75e+06 x  + 2.164e+07 x  - 1.85e+07 x  - 2.934e+07 x \n",
      "              12             11             10             9\n",
      " + 6.199e+07 x  - 1.568e+07 x  - 5.103e+07 x  + 5.415e+07 x\n",
      "              8             7             6             5            4\n",
      " - 1.327e+07 x - 1.217e+07 x + 1.171e+07 x - 4.655e+06 x + 1.03e+06 x\n",
      "              3        2\n",
      " - 1.298e+05 x + 8653 x - 249.8 x + 2.113\n"
     ]
    }
   ],
   "source": [
    "model16=polynomial_regression(data,16)\n",
    "print_coefficients(model16)\n",
    "plot_poly_predictions(data,model16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "#Ridge Regression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ridge regression aims to avoid overfitting by adding a cost to the RSS term of standard least squares that depends on the 2-norm of the coefficients ∥w∥. The result is penalizing fits with large coefficients. The strength of this penalty, and thus the fit vs. model complexity balance, is controled by a parameter lambda (here called \"L2_penalty\").\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Define our function to solve the ridge objective for a polynomial regression model of any degree:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polynomial_ridge_regression(data, deg, l2_penalty):\n",
    "    model = graphlab.linear_regression.create(polynomial_features(data,deg), \n",
    "                                              target='Y', l2_penalty=l2_penalty,\n",
    "                                              validation_set=None,verbose=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Perform a ridge fit of a degree-16 polynomial using a very small penalty strength\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned polynomial for degree 16:\n",
      "           16             15            14             13\n",
      "-5.75e+06 x  + 2.164e+07 x  - 1.85e+07 x  - 2.934e+07 x \n",
      "              12             11             10             9\n",
      " + 6.199e+07 x  - 1.568e+07 x  - 5.103e+07 x  + 5.415e+07 x\n",
      "              8             7             6             5            4\n",
      " - 1.327e+07 x - 1.217e+07 x + 1.171e+07 x - 4.655e+06 x + 1.03e+06 x\n",
      "              3        2\n",
      " - 1.298e+05 x + 8653 x - 249.8 x + 2.113\n"
     ]
    }
   ],
   "source": [
    "model16_2 = polynomial_ridge_regression(data, deg=16, l2_penalty=1e-25)\n",
    "print_coefficients(model16_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Perform a ridge fit of a degree-16 polynomial using a very large penalty strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned polynomial for degree 16:\n",
      "         16          15          14         13          12          11\n",
      "-0.1658 x  - 0.1621 x  - 0.1585 x  - 0.155 x  - 0.1516 x  - 0.1479 x \n",
      "          10          9          8          7          6          5\n",
      " - 0.144 x  - 0.1396 x - 0.1343 x - 0.1278 x - 0.1194 x - 0.1084 x\n",
      "            4           3           2\n",
      " - 0.09384 x - 0.07429 x - 0.04825 x - 0.01687 x + 0.6768\n"
     ]
    }
   ],
   "source": [
    "model16_3 = polynomial_ridge_regression(data, deg=16, l2_penalty=100)\n",
    "print_coefficients(model16_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_poly_predictions(data,model16_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Let's look at fits for a sequence of increasing lambda values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 1.00e-25\n",
      "Learned polynomial for degree 16:\n",
      "           16             15            14             13\n",
      "-5.75e+06 x  + 2.164e+07 x  - 1.85e+07 x  - 2.934e+07 x \n",
      "              12             11             10             9\n",
      " + 6.199e+07 x  - 1.568e+07 x  - 5.103e+07 x  + 5.415e+07 x\n",
      "              8             7             6             5            4\n",
      " - 1.327e+07 x - 1.217e+07 x + 1.171e+07 x - 4.655e+06 x + 1.03e+06 x\n",
      "              3        2\n",
      " - 1.298e+05 x + 8653 x - 249.8 x + 2.113\n",
      "\n",
      "\n",
      "lambda = 1.00e-10\n",
      "Learned polynomial for degree 16:\n",
      "           16             15        14             13             12\n",
      "4.636e+04 x  - 9.651e+04 x  + 6972 x  + 6.553e+04 x  + 2.517e+04 x \n",
      "              11             10             9             8        7\n",
      " - 3.809e+04 x  - 4.182e+04 x  + 1.193e+04 x + 4.017e+04 x - 5416 x\n",
      "             6             5             4        3         2\n",
      " - 3.46e+04 x + 3.005e+04 x - 1.227e+04 x + 2875 x - 364.8 x + 19.54 x + 0.3422\n",
      "\n",
      "\n",
      "lambda = 1.00e-06\n",
      "Learned polynomial for degree 16:\n",
      "        16         15         14         13          12         11\n",
      "-46.85 x  + 17.24 x  + 88.55 x  + 84.06 x  + 0.9253 x  - 104.8 x \n",
      "        10         9        8       7       6         5         4\n",
      " - 154 x  - 92.51 x + 61.2 x + 195 x + 152 x - 105.2 x - 255.7 x\n",
      "          3        2\n",
      " + 193.4 x - 34.5 x + 1.189 x + 0.5419\n",
      "\n",
      "\n",
      "lambda = 1.00e-03\n",
      "Learned polynomial for degree 16:\n",
      "       16          15         14         13         12         11\n",
      "13.22 x  - 0.6562 x  - 8.038 x  - 10.03 x  - 7.863 x  - 2.986 x \n",
      "          10         9         8         7         6         5\n",
      " + 2.936 x  + 8.013 x + 10.29 x + 8.176 x + 1.329 x - 7.915 x\n",
      "          4         3         2\n",
      " - 13.14 x - 5.507 x + 12.29 x - 1.615 x + 0.4888\n",
      "\n",
      "\n",
      "lambda = 1.00e+02\n",
      "Learned polynomial for degree 16:\n",
      "         16          15          14         13          12          11\n",
      "-0.1658 x  - 0.1621 x  - 0.1585 x  - 0.155 x  - 0.1516 x  - 0.1479 x \n",
      "          10          9          8          7          6          5\n",
      " - 0.144 x  - 0.1396 x - 0.1343 x - 0.1278 x - 0.1194 x - 0.1084 x\n",
      "            4           3           2\n",
      " - 0.09384 x - 0.07429 x - 0.04825 x - 0.01687 x + 0.6768\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for l2_penalty in [1e-25, 1e-10, 1e-6, 1e-3, 1e2]:\n",
    "    model = polynomial_ridge_regression(data, deg=16, l2_penalty=l2_penalty)\n",
    "    print 'lambda = %.2e' % l2_penalty\n",
    "    print_coefficients(model)\n",
    "    print '\\n'\n",
    "    plt.figure()\n",
    "    plot_poly_predictions(data,model)\n",
    "    plt.title('Ridge, lambda = %.2e' % l2_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "#Perform a ridge fit of a degree-16 polynomial using a \"good\" penalty strength\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We will learn about cross validation later in this course as a way to select a good value of the tuning parameter (penalty strength) lambda. Here, we consider \"leave one out\" (LOO) cross validation, which one can show approximates average mean square error (MSE). As a result, choosing lambda to minimize the LOO error is equivalent to choosing lambda to minimize an approximation to average MSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOO- Returns the average MSE\n",
    "\n",
    "def loo(data, degree, l2_penalty_values):\n",
    "    #Create polynomial features\n",
    "    polynomial_features(data, degree)\n",
    "    \n",
    "    # Create folds for cross validatation- number of folds= number of data points\n",
    "    num_folds=len(data)\n",
    "    folds=graphlab.cross_validation.KFold(data, num_folds)\n",
    "    \n",
    "    # for each value of l2_penalty, fit a model for each fold and compute average MSE\n",
    "    l2_penalty_mse=[]\n",
    "    min_mse=None\n",
    "    best_l2_penalty=None\n",
    "    for l2_penalty_value in l2_penalty_values:\n",
    "        next_mse=0.0\n",
    "        for train_set, validation_set in folds:\n",
    "            #train model\n",
    "            model=graphlab.linear_regression.create(train_set, target='Y', l2_penalty=l2_penalty_value, validation_set=None, verbose=False)\n",
    "            \n",
    "            #predict on validation set\n",
    "            y_predicted=model.predict(validation_set)\n",
    "\n",
    "            #compute squared error\n",
    "            next_mse +=((y_predicted-validation_set['Y'])**2).sum()\n",
    "        \n",
    "        # save squared error in list of MSE for each l2_penalty\n",
    "        next_mse = next_mse/num_folds\n",
    "        l2_penalty_mse.append(next_mse)\n",
    "        if min_mse is None or next_mse < min_mse:\n",
    "            min_mse = next_mse\n",
    "            best_l2_penalty = l2_penalty_value\n",
    "    \n",
    "    return l2_penalty_mse,best_l2_penalty    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Run LOO cross validation for \"num\" values of lambda, on a log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_penalty_values = np.logspace(-4, 10, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-04,   3.59381366e-03,   1.29154967e-01,\n",
       "         4.64158883e+00,   1.66810054e+02,   5.99484250e+03,\n",
       "         2.15443469e+05,   7.74263683e+06,   2.78255940e+08,\n",
       "         1.00000000e+10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_penalty_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_penalty_mse,best_l2_penalty = loo(data, 16, l2_penalty_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23138098383654065,\n",
       " 0.23137349679013852,\n",
       " 0.23113535636203864,\n",
       " 0.23974667561854116,\n",
       " 0.31456516408512686,\n",
       " 0.3233404978495715,\n",
       " 0.32360301408259506,\n",
       " 0.323610333882086,\n",
       " 0.3236105375715853,\n",
       " 0.32361054323937594]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_penalty_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12915496650148839"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_l2_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results of estimating LOO for each value of lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(l2_penalty_values,l2_penalty_mse,'k-')\n",
    "plt.xlabel('$\\L2_penalty$')\n",
    "plt.ylabel('LOO cross validation error')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned polynomial for degree 16:\n",
      "         16          15          14          13         12          11\n",
      "0.01707 x  + 0.2724 x  + 0.4717 x  + 0.6001 x  + 0.642 x  + 0.5826 x \n",
      "           10          9         8          7         6         5\n",
      " + 0.4099 x  + 0.1187 x - 0.282 x - 0.7571 x - 1.227 x - 1.543 x\n",
      "          4          3          2\n",
      " - 1.473 x - 0.7397 x + 0.6641 x + 1.425 x + 0.3663\n"
     ]
    }
   ],
   "source": [
    "model16_4 = polynomial_ridge_regression(data, deg=16, l2_penalty=best_l2_penalty)\n",
    "print_coefficients(model16_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "#Lasso Regression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Lasso regression jointly shrinks coefficients to avoid overfitting, and implicitly performs feature selection by setting some coefficients exactly to 0 for sufficiently large penalty strength lambda (here called \"L1_penalty\"). In particular, lasso takes the RSS term of standard least squares and adds a 1-norm cost of the coefficients ∥w∥.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Define our function to solve the lasso objective for a polynomial regression model of any degree:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polynomial_lasso_regression(data, deg, l1_penalty):\n",
    "    model = graphlab.linear_regression.create(polynomial_features(data,deg), \n",
    "                                              target='Y', l2_penalty=0.,\n",
    "                                              l1_penalty=l1_penalty,\n",
    "                                              validation_set=None, \n",
    "                                              solver='fista', verbose=False,\n",
    "                                              max_iterations=3000, convergence_threshold=1e-10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "#Explore the lasso solution as a function of a few different penalty strengths\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We refer to lambda in the lasso case below as \"l1_penalty\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_penalty = 1.000000e-04\n",
      "number of nonzeros = 17\n",
      "Learned polynomial for degree 16:\n",
      "       16         15         14         13         12         11\n",
      "42.82 x  + 3.809 x  - 18.37 x  - 27.14 x  - 24.48 x  - 13.87 x \n",
      "           10         9         8         7         6         5\n",
      " + 0.1423 x  + 14.27 x + 22.78 x + 21.43 x + 8.656 x - 11.34 x\n",
      "          4         3        2\n",
      " - 25.38 x - 12.61 x + 23.2 x - 4.328 x + 0.6297\n",
      "\n",
      "\n",
      "l1_penalty = 1.000000e-02\n",
      "number of nonzeros = 16\n",
      "Learned polynomial for degree 16:\n",
      "         16         15          14            13          11\n",
      "-0.7469 x  - 2.804 x  - 0.8283 x  - 0.002653 x  + 0.2012 x \n",
      "             10       9         8          7          6          5\n",
      " - 0.002729 x  + 1.7 x + 8.727 x + 0.8003 x + 0.2017 x - 0.1724 x\n",
      "          4           3         2\n",
      " - 16.11 x - 0.01174 x + 7.863 x - 0.6322 x + 0.4429\n",
      "\n",
      "\n",
      "l1_penalty = 1.000000e-01\n",
      "number of nonzeros = 5\n",
      "Learned polynomial for degree 16:\n",
      "       15           14         4\n",
      "1.448 x  + 0.02838 x  - 4.266 x + 1.924 x + 0.2936\n",
      "\n",
      "\n",
      "l1_penalty = 1.000000e+01\n",
      "number of nonzeros = 3\n",
      "Learned polynomial for degree 16:\n",
      "        7          6\n",
      "-0.854 x - 0.3654 x + 0.6292\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for l1_penalty in [0.0001, 0.01, 0.1, 10]:\n",
    "    model = polynomial_lasso_regression(data, deg=16, l1_penalty=l1_penalty)\n",
    "    print 'l1_penalty = %e' % l1_penalty\n",
    "    print 'number of nonzeros = %d' % (model.coefficients['value']).nnz()\n",
    "    print_coefficients(model)\n",
    "    print '\\n'\n",
    "    plt.figure()\n",
    "    plot_poly_predictions(data,model)\n",
    "    plt.title('LASSO, lambda = %.2e, # nonzeros = %d' % (l1_penalty, (model.coefficients['value']).nnz()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: We see that as lambda increases, we get sparser and sparser solutions. However, even for our non-sparse case for lambda=0.0001, the fit of our high-order polynomial is not too wild. This is because, like in ridge, coefficients included in the lasso solution are shrunk relative to those of the least squares (unregularized) solution. This leads to better behavior even without sparsity. Of course, as lambda goes to 0, the amount of this shrinkage decreases and the lasso solution approaches the (wild) least squares solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
